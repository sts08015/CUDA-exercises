{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cFjNPtYt9ObU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <cmath>\n",
        "\n",
        "enum {FAIL, SUCCESS};\n",
        "\n",
        "__global__ void vectorAdd(int* vec1,int* vec2, int* res, int size)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(idx < size) res[idx] = vec1[idx] + vec2[idx];\n",
        "}\n",
        "\n",
        "void init_vector(int* vec,const int size)\n",
        "{\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_int_distribution<int> dis(0, 99);\n",
        "    \n",
        "    for(int i=0;i<size;i++) vec[i] = dis(gen);\n",
        "}\n",
        "\n",
        "int verifier(int* vec1, int* vec2, int* res, int size)\n",
        "{\n",
        "    for(int i=0;i<size;i++)\n",
        "    {\n",
        "        if(vec1[i]+vec2[i] != res[i]) return FAIL;\n",
        "    }\n",
        "    return SUCCESS;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int N = 1 << 16;  //vector size (65536)\n",
        "    int size = N*sizeof(int);\n",
        "    int *h_a, *h_b, *h_c; //host vector\n",
        "    int *d_a, *d_b, *d_c; //device vector\n",
        " \n",
        "    h_a = new int[N];\n",
        "    h_b = new int[N];\n",
        "    h_c = new int[N];\n",
        "  \n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    init_vector(h_a,N);\n",
        "    init_vector(h_b,N);\n",
        "\n",
        "    cudaMemcpy(d_a,h_a,size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,h_b,size,cudaMemcpyHostToDevice);\n",
        "\n",
        "    const int NUM_THREADS = 64;\n",
        "    const int NUM_BLOCKS = (int)ceil(N/NUM_THREADS);\n",
        "\n",
        "    vectorAdd<<<NUM_BLOCKS,NUM_THREADS>>>(d_a,d_b,d_c,N);\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if(verifier(h_a,h_b,h_c,N) == SUCCESS) std::cout<<\"YAY!\";\n",
        "    else std::cout << \"Hmm..\";\n",
        " \n",
        "    delete[] h_a;\n",
        "    delete[] h_b;\n",
        "    delete[] h_c;\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_HmHaW0IaqM",
        "outputId": "a4654e1c-9bfb-459c-980c-d5c41788dec0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAY!\n"
          ]
        }
      ]
    }
  ]
}